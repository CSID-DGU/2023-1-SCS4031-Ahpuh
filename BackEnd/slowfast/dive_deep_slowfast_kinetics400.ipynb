{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet-cu112\n",
      "  Using cached mxnet_cu112-1.9.1-py3-none-manylinux2014_x86_64.whl (499.4 MB)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/irteam/anaconda3/lib/python3.7/site-packages (from mxnet-cu112) (0.8.4)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from mxnet-cu112) (1.18.1)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from mxnet-cu112) (2.22.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet-cu112) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet-cu112) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet-cu112) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet-cu112) (2019.11.28)\n",
      "Installing collected packages: mxnet-cu112\n",
      "Successfully installed mxnet-cu112-1.9.1\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  libnccl2\n",
      "0 upgraded, 1 newly installed, 0 to remove and 177 not upgraded.\n",
      "Need to get 97.5 MB of archives.\n",
      "After this operation, 268 MB of additional disk space will be used.\n",
      "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnccl2 2.15.5-1+cuda11.8 [97.5 MB]\n",
      "Fetched 97.5 MB in 2s (42.6 MB/s)   \u001b[0m33m\u001b[33m\u001b[33m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libnccl2.\n",
      "(Reading database ... 82778 files and directories currently installed.)\n",
      "Preparing to unpack .../libnccl2_2.15.5-1+cuda11.8_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking libnccl2 (2.15.5-1+cuda11.8) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Setting up libnccl2 (2.15.5-1+cuda11.8) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JW: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-chrome.list:3 and /etc/apt/sources.list.d/google.list:1\n",
      "W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-chrome.list:3 and /etc/apt/sources.list.d/google.list:1\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet-cu112\n",
    "!sudo apt install libnccl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gluoncv in /home/irteam/anaconda3/lib/python3.7/site-packages (0.10.5.post0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /home/irteam/anaconda3/lib/python3.7/site-packages (from gluoncv) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: portalocker in /home/irteam/anaconda3/lib/python3.7/site-packages (from gluoncv) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /home/irteam/anaconda3/lib/python3.7/site-packages (from gluoncv) (5.3)\n",
      "Requirement already satisfied, skipping upgrade: yacs in /home/irteam/anaconda3/lib/python3.7/site-packages (from gluoncv) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: autocfg in /home/irteam/anaconda3/lib/python3.7/site-packages (from gluoncv) (0.0.8)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /home/irteam/anaconda3/lib/python3.7/site-packages (from gluoncv) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /home/irteam/anaconda3/lib/python3.7/site-packages (from gluoncv) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: opencv-python in /home/irteam/anaconda3/lib/python3.7/site-packages (from gluoncv) (4.7.0.72)\n",
      "Requirement already satisfied, skipping upgrade: Pillow in /home/irteam/anaconda3/lib/python3.7/site-packages (from gluoncv) (7.0.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /home/irteam/anaconda3/lib/python3.7/site-packages (from gluoncv) (4.42.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /home/irteam/anaconda3/lib/python3.7/site-packages (from gluoncv) (3.1.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /home/irteam/anaconda3/lib/python3.7/site-packages (from gluoncv) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests->gluoncv) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests->gluoncv) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests->gluoncv) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests->gluoncv) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /home/irteam/anaconda3/lib/python3.7/site-packages (from pandas->gluoncv) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /home/irteam/anaconda3/lib/python3.7/site-packages (from pandas->gluoncv) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /home/irteam/anaconda3/lib/python3.7/site-packages (from matplotlib->gluoncv) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/irteam/anaconda3/lib/python3.7/site-packages (from matplotlib->gluoncv) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /home/irteam/anaconda3/lib/python3.7/site-packages (from matplotlib->gluoncv) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/irteam/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->gluoncv) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/irteam/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->gluoncv) (45.2.0.post20200210)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gluoncv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Dive Deep into Training SlowFast mdoels on Kinetcis400\n",
    "\n",
    "This is a video action recognition tutorial using Gluon CV toolkit, a step-by-step example.\n",
    "The readers should have basic knowledge of deep learning and should be familiar with Gluon API.\n",
    "New users may first go through `A 60-minute Gluon Crash Course <http://gluon-crash-course.mxnet.io/>`_.\n",
    "You can `Start Training Now`_ or `Dive into Deep`_.\n",
    "\n",
    "## Start Training Now\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Feel free to skip the tutorial because the training script is self-complete and ready to launch.\n",
    "\n",
    "    :download:`Download Full Python Script: train_recognizer.py<../../../scripts/action-recognition/train_recognizer.py>`\n",
    "\n",
    "    For more training command options, please run ``python train_recognizer.py -h``\n",
    "    Please checkout the `model_zoo <../model_zoo/index.html#action_recognition>`_ for training commands of reproducing the pretrained model.</p></div>\n",
    "\n",
    "\n",
    "### Network Structure\n",
    "\n",
    "First, let's import the necessary libraries into python.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet-cu101\n",
      "  Downloading mxnet_cu101-1.9.1-py3-none-manylinux2014_x86_64.whl (360.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 360.0 MB 29 kB/s /s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/irteam/anaconda3/lib/python3.7/site-packages (from mxnet-cu101) (0.8.4)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from mxnet-cu101) (1.18.1)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/irteam/anaconda3/lib/python3.7/site-packages (from mxnet-cu101) (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet-cu101) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/irteam/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.25.8)\n",
      "Installing collected packages: mxnet-cu101\n",
      "Successfully installed mxnet-cu101-1.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet-cu101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irteam/anaconda3/lib/python3.7/site-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.9.1` and `torch==1.13.1+cu117` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
      "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import argparse, time, logging, os, sys, math\n",
    "\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import gluoncv as gcv\n",
    "from mxnet import gluon, nd, init, context\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "from gluoncv.data.transforms import video\n",
    "\n",
    "from gluoncv.data import Kinetics400\n",
    "from gluoncv.model_zoo import get_model\n",
    "from gluoncv.utils import makedirs, LRSequential, LRScheduler, split_and_load, TrainingHistory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we pick a widely adopted model, ``SlowFast``, for the tutorial.\n",
    "`SlowFast <https://arxiv.org/abs/1812.03982>`_ is a new 3D video\n",
    "classification model, aiming for best trade-off between accuracy and efficiency.\n",
    "It proposes two branches, fast branch and slow branch, to handle different aspects in a video.\n",
    "Fast branch is to capture motion dynamics by using many but small video frames.\n",
    "Slow branch is to capture fine apperance details by using few but large video frames.\n",
    "Features from two branches are combined using lateral connections.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SlowFast(\n",
      "  (fast_conv1): Conv3D(3 -> 8, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "  (fast_bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
      "  (fast_relu): Activation(relu)\n",
      "  (fast_maxpool): MaxPool3D(size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
      "  (fast_res2): HybridSequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv3D(8 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
      "      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
      "      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (relu): Activation(relu)\n",
      "      (downsample): HybridSequential(\n",
      "        (0): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv3D(32 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
      "      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
      "      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv3D(32 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
      "      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
      "      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "  )\n",
      "  (fast_res3): HybridSequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv3D(32 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
      "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
      "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (relu): Activation(relu)\n",
      "      (downsample): HybridSequential(\n",
      "        (0): Conv3D(32 -> 64, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
      "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
      "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
      "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
      "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
      "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
      "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "  )\n",
      "  (fast_res4): HybridSequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv3D(64 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (relu): Activation(relu)\n",
      "      (downsample): HybridSequential(\n",
      "        (0): Conv3D(64 -> 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "  )\n",
      "  (fast_res5): HybridSequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv3D(128 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (relu): Activation(relu)\n",
      "      (downsample): HybridSequential(\n",
      "        (0): Conv3D(128 -> 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "  )\n",
      "  (lateral_p1): HybridSequential(\n",
      "    (0): Conv3D(8 -> 16, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
      "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
      "    (2): Activation(relu)\n",
      "  )\n",
      "  (lateral_res2): HybridSequential(\n",
      "    (0): Conv3D(32 -> 64, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
      "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "    (2): Activation(relu)\n",
      "  )\n",
      "  (lateral_res3): HybridSequential(\n",
      "    (0): Conv3D(64 -> 128, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
      "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "    (2): Activation(relu)\n",
      "  )\n",
      "  (lateral_res4): HybridSequential(\n",
      "    (0): Conv3D(128 -> 256, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
      "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "    (2): Activation(relu)\n",
      "  )\n",
      "  (slow_conv1): Conv3D(3 -> 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
      "  (slow_bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "  (slow_relu): Activation(relu)\n",
      "  (slow_maxpool): MaxPool3D(size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
      "  (slow_res2): HybridSequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv3D(80 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (relu): Activation(relu)\n",
      "      (downsample): HybridSequential(\n",
      "        (0): Conv3D(80 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv3D(256 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv3D(256 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "  )\n",
      "  (slow_res3): HybridSequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv3D(320 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (relu): Activation(relu)\n",
      "      (downsample): HybridSequential(\n",
      "        (0): Conv3D(320 -> 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "  )\n",
      "  (slow_res4): HybridSequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv3D(640 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "      (relu): Activation(relu)\n",
      "      (downsample): HybridSequential(\n",
      "        (0): Conv3D(640 -> 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "  )\n",
      "  (slow_res5): HybridSequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv3D(1280 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "      (relu): Activation(relu)\n",
      "      (downsample): HybridSequential(\n",
      "        (0): Conv3D(1280 -> 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "      (relu): Activation(relu)\n",
      "    )\n",
      "  )\n",
      "  (avg): GlobalAvgPool3D(size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0), ceil_mode=True, global_pool=True, pool_type=avg, layout=NCDHW)\n",
      "  (dp): Dropout(p = 0.5, axes=())\n",
      "  (fc): Dense(2304 -> 3, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# number of GPUs to use\n",
    "num_gpus = 2\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
    "\n",
    "# Get the model slowfast_4x16_resnet50_kinetics400 with 400 output classes, without pre-trained weights\n",
    "net = get_model(name='slowfast_4x16_resnet50_kinetics400', nclass=3)\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "print(net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation and Data Loader\n",
    "\n",
    "Data augmentation for video is different from image. For example, if you\n",
    "want to randomly crop a video sequence, you need to make sure all the video\n",
    "frames in this sequence undergo the same cropping process. We provide a\n",
    "new set of transformation functions, working with multiple images.\n",
    "Please checkout the `video.py <../../../gluoncv/data/transforms/video.py>`_ for more details.\n",
    "Most video data augmentation strategies used here are introduced in [Wang15]_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    # Fix the input video frames size as 256×340 and randomly sample the cropping width and height from\n",
    "    # {256,224,192,168}. After that, resize the cropped regions to 224 × 224.\n",
    "    video.VideoCenterCrop(size=(224, 224)),\n",
    "    # Randomly flip the video frames horizontally\n",
    "    video.VideoRandomHorizontalFlip(),\n",
    "    # Transpose the video frames from height*width*num_channels to num_channels*height*width\n",
    "    # and map values from [0, 255] to [0,1]\n",
    "    video.VideoToTensor(),\n",
    "    # Normalize the video frames with mean and standard deviation calculated across all images\n",
    "    video.VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the transform functions, we can define data loaders for our\n",
    "training datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 56 training samples.\n"
     ]
    }
   ],
   "source": [
    "# Batch Size for Each GP\n",
    "per_device_batch_size = 10\n",
    "# Number of data loader workers\n",
    "num_workers = 0\n",
    "# Calculate effective total batch size\n",
    "batch_size = per_device_batch_size * num_gpus\n",
    "\n",
    "\n",
    "# Set train=True for training the model.\n",
    "# ``new_length`` indicates the number of frames we will cover.\n",
    "# For SlowFast network, we evenly sample 32 frames for the fast branch and 4 frames for the slow branch.\n",
    "# This leads to the actual input length of 36 video frames.\n",
    "train_dataset = Kinetics400(train=True, new_length=64, slowfast=True, transform=transform_train, root='/home/irteam/didwldn3032-dcloud-dir/didwldn3032/swim_dataset/rawframes_train', setting='/home/irteam/didwldn3032-dcloud-dir/didwldn3032/swim_dataset/swim_train_list_rawframes.txt')\n",
    "print('Load %d training samples.' % len(train_dataset))\n",
    "train_data = gluon.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                   shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer, Loss and Metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lr_decay = 0.1\n",
    "warmup_epoch = 34\n",
    "total_epoch = 196\n",
    "num_batches = len(train_data)\n",
    "lr_scheduler = LRSequential([\n",
    "    LRScheduler('linear', base_lr=0.01, target_lr=0.1,\n",
    "                nepochs=warmup_epoch, iters_per_epoch=num_batches),\n",
    "    LRScheduler('cosine', base_lr=0.1, target_lr=0,\n",
    "                nepochs=total_epoch - warmup_epoch,\n",
    "                iters_per_epoch=num_batches,\n",
    "                step_factor=lr_decay, power=2)\n",
    "])\n",
    "\n",
    "# Stochastic gradient descent\n",
    "optimizer = 'sgd'\n",
    "# Set parameters\n",
    "optimizer_params = {'learning_rate': 0.01, 'wd': 0.0001, 'momentum': 0.9}\n",
    "optimizer_params['lr_scheduler'] = lr_scheduler\n",
    "\n",
    "# Define our trainer for net\n",
    "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to optimize our model, we need a loss function.\n",
    "For classification tasks, we usually use softmax cross entropy as the\n",
    "loss function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we use accuracy as the metric to monitor our training\n",
    "process. Besides, we record metric values, and will print them at the\n",
    "end of training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_metric = mx.metric.Accuracy()\n",
    "train_history = TrainingHistory(['training-acc'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "After all the preparations, we can finally start training!\n",
    "Following is the script.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>In order to finish the tutorial quickly, we only train for 0 epoch on a tiny subset of Kinetics400,\n",
    "  and 100 iterations per epoch. In your experiments, we recommend setting ``epochs=100`` for the full Kinetics400 dataset.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] train=0.464286 loss=2.267660 time: 26.932033\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-77b7e4811153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Loop through each batch of training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Extract data and label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_and_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meven_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;31m# ensure a single iter would not using twice.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_reload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/dataloader.py\u001b[0m in \u001b[0;36msame_process_iter\u001b[0;34m()\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0msame_process_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_sampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batchify_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_pinned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_device_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/gluon/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0msame_process_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_sampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batchify_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_pinned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_device_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gluoncv/data/video_custom/classification.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mclip_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslowfast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/gluon/nn/basic_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gluoncv/data/transforms/video.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, clips)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mnew_clips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcur_img\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclips\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mnew_clips\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_intensity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_clips\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    train_metric.reset()\n",
    "    train_loss = 0\n",
    "\n",
    "    # Loop through each batch of training data\n",
    "    for i, batch in enumerate(train_data):\n",
    "        # Extract data and label\n",
    "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "\n",
    "        # AutoGrad\n",
    "        with ag.record():\n",
    "            output = []\n",
    "            for _, X in enumerate(data):\n",
    "                X = X.reshape((-1,) + X.shape[2:])\n",
    "                pred = net(X)\n",
    "                output.append(pred)\n",
    "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
    "\n",
    "        # Backpropagation\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "\n",
    "        # Optimize\n",
    "        trainer.step(batch_size)\n",
    "\n",
    "        # Update metrics\n",
    "        train_loss += sum([l.mean().asscalar() for l in loss])\n",
    "        train_metric.update(label, output)\n",
    "\n",
    "        if i == 100:\n",
    "            break\n",
    "\n",
    "    name, acc = train_metric.get()\n",
    "\n",
    "    # Update history and print metrics\n",
    "    train_history.update([acc])\n",
    "    print('[Epoch %d] train=%f loss=%f time: %f' %\n",
    "        (epoch, acc, train_loss / (i+1), time.time()-tic))\n",
    "\n",
    "# We can plot the metric scores with:\n",
    "train_history.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(batch[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "file_name = \"/home/irteam/didwldn3032-dcloud-dir/didwldn3032/2023-1-SCS4031-Ahpuh/net.params\"\n",
    "net.save_parameters(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"/home/irteam/didwldn3032-dcloud-dir/didwldn3032/2023-1-SCS4031-Ahpuh/net.params\"\n",
    "\n",
    "new_net = get_model(name='slowfast_4x16_resnet50_kinetics400', nclass=3)\n",
    "new_net.load_parameters(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.utils.filesystem import try_import_decord\n",
    "decord = try_import_decord()\n",
    "\n",
    "vr = decord.VideoReader('/home/irteam/didwldn3032-dcloud-dir/다이빙.mp4')\n",
    "fast_frame_id_list = range(0, 64, 2)\n",
    "slow_frame_id_list = range(0, 64, 16)\n",
    "frame_id_list = list(fast_frame_id_list) + list(slow_frame_id_list)\n",
    "video_data = vr.get_batch(frame_id_list).asnumpy()\n",
    "clip_input = [video_data[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n",
      "(148, 224, 224, 3)\n",
      "(36, 224, 224, 3)\n",
      "Video data is downloaded and preprocessed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "input_file = '/home/irteam/didwldn3032-dcloud-dir/다이빙.mp4'\n",
    "cap = cv2.VideoCapture(input_file)\n",
    "\n",
    "result = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    # Resize the frame\n",
    "    print(frame.shape)\n",
    "    resized_frame = cv2.resize(frame, (224, 224))\n",
    "    result.append(resized_frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "result = np.array(result)\n",
    "print(result.shape)\n",
    "\n",
    "fast_frame_id_list = range(0, 64, 2)\n",
    "slow_frame_id_list = range(0, 64, 16)\n",
    "frame_id_list = list(fast_frame_id_list) + list(slow_frame_id_list)\n",
    "clip_input = [result[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]\n",
    "print(np.array(clip_input).shape)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    # Fix the input video frames size as 256×340 and randomly sample the cropping width and height from\n",
    "    # {256,224,192,168}. After that, resize the cropped regions to 224 × 224.\n",
    "    #video.ShortSideRescale(224),\n",
    "    # Randomly flip the video frames horizontally\n",
    "    #video.VideoRandomHorizontalFlip(),\n",
    "    # Transpose the video frames from height*width*num_channels to num_channels*height*width\n",
    "    # and map values from [0, 255] to [0,1]\n",
    "    video.VideoToTensor(),\n",
    "    # Normalize the video frames with mean and standard deviation calculated across all images\n",
    "    video.VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# transform_fn = video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "clip_input = transform_train(clip_input)\n",
    "clip_input = np.stack(clip_input, axis=0)\n",
    "clip_input = clip_input.reshape((-1,) + (36, 3, 224, 224))\n",
    "clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\n",
    "print('Video data is downloaded and preprocessed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0. 2. 1.]\n",
       "<NDArray 3 @cpu(0)>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = new_net(nd.array(clip_input))\n",
    "nd.topk(pred, k=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n",
      "finish img saving\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "for i in range(36):\n",
    "    img = Image.fromarray(np.transpose(clip_input, (0, 2, 3, 4, 1))[0][i], 'RGB')\n",
    "    # img = Image.fromarray(clip_input[i], 'RGB')\n",
    "    img.save('/home/irteam/didwldn3032-dcloud-dir/didwldn3032/2023-1-SCS4031-Ahpuh/test_imgs/img%s.jpg'%i)\n",
    "    print(\"finish img saving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input video clip is classified to be\n",
      "probability 0.982.\n",
      "probability 0.018.\n",
      "probability 0.000.\n"
     ]
    }
   ],
   "source": [
    "label = {0:'diving', 1:'drown', 2:'falldown'}\n",
    "topK = 3\n",
    "ind = nd.topk(pred, k=topK)[0].astype('int')\n",
    "print('The input video clip is classified to be')\n",
    "for i in range(topK):\n",
    "    print('probability %.3f.'%\n",
    "          (nd.softmax(pred)[0][ind[i]].asscalar()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the tiny subset, the accuracy number is quite low.\n",
    "You can `Start Training Now`_ on the full Kinetics400 dataset.\n",
    "\n",
    "### References\n",
    "\n",
    ".. [Wang15] Limin Wang, Yuanjun Xiong, Zhe Wang, and Yu Qiao. \\\n",
    "    \"Towards Good Practices for Very Deep Two-Stream ConvNets.\" \\\n",
    "    arXiv preprint arXiv:1507.02159 (2015).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
